{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " RN50_FYP_Munchies",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoOkdH/g9D5hY7b31FKuAe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AditiShanmugam/Multi-Modal-Machine-Learning/blob/main/RN50_FYP_Munchies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_sAi8z2IXE8",
        "outputId": "7831ad15-6fb7-45d8-a940-5d45b88066aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA version: 11.1\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        " \n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        " \n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "  torch_version_suffix = \"+cu110\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eWiQKndIZ2N",
        "outputId": "975200ba-57dd-445e-8a16-3e325ceb38b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
            "\u001b[K     |███████████▎                    | 407.0 MB 1.2 MB/s eta 0:10:10"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install ftfy regex\n",
        "\n",
        "import torch\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4o3c3AuYQvr3"
      },
      "outputs": [],
      "source": [
        "#Checking for GPU:\n",
        "batch_size=50\n",
        "from torch import cuda\n",
        "train_on_gpu = cuda.is_available()\n",
        "print(f'Train on gpu: {train_on_gpu}')\n",
        "if train_on_gpu:\n",
        "    gpu_count = cuda.device_count()\n",
        "    print(f'{gpu_count} gpus detected.')\n",
        "    if gpu_count > 1:\n",
        "        multi_gpu = True\n",
        "    else:\n",
        "        multi_gpu = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVrG0g0DIgZW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_883vlVInAh"
      },
      "outputs": [],
      "source": [
        "# make directory to hold images\n",
        "import os \n",
        "\n",
        "#if 'images' not in os.listdir():\n",
        "#!mkdir /content/images/\n",
        "# !rm -r /content/images/\n",
        "\n",
        "# unzip and extract\n",
        "# !cp -r /content/gdrive/MyDrive/Exotic_Food_Dataset/ExoticFood/ /content/images/\n",
        "!unzip -uq '/content/gdrive/MyDrive/FinalYearProject-Group11/Datasets/Image_Database_Munchies.zip' -d \"/content/images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdQojtU6NMd8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "!mkdir data/\n",
        "!rm -rf data/\n",
        "!rm -rf data/train\n",
        "!rm -rf data/test\n",
        "!rm -rf data/val\n",
        "!mkdir data/\n",
        "!mkdir data/train\n",
        "!mkdir data/test\n",
        "!mkdir data/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Qq6Jzs8NXJ5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "image_urls = []\n",
        "labels = []\n",
        "\n",
        "path = '/content/images/Image_Database_Munchies'\n",
        "\n",
        "\n",
        "for folder in os.listdir(path):\n",
        "  if folder != '.DS_Store':\n",
        "    for file in os.listdir(os.path.join(path, folder)):\n",
        "      if file != '.DS_Store':\n",
        "        url = os.path.join(path, folder, file)\n",
        "        image_urls.append(url)\n",
        "        name = folder#.replace('_',' ')\n",
        "        labels.append(name)\n",
        "\n",
        "\n",
        "print(f'# of images: {len(image_urls)}')\n",
        "print(f'# of labels: {len(labels)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3498MuxFNYNm"
      },
      "outputs": [],
      "source": [
        "class_to_idx = {v:k for k,v in enumerate(sorted(set(labels)))}\n",
        "idx_to_class = {k:v for v,k in class_to_idx.items()}\n",
        "\n",
        "list_of_targets = [class_to_idx[label] for label in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXyuLygvNdIv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(list(zip(image_urls, labels, list_of_targets)), columns = ['image_urls', 'labels', 'targets'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CupJ6lNMNMXe"
      },
      "outputs": [],
      "source": [
        "Names = sorted(set(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo7wXhmNNv0S"
      },
      "outputs": [],
      "source": [
        "n_classes = len(Names)\n",
        "print('Number of classes:',n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPo4dzCiNMRR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, _, _ = train_test_split(df, df['labels'],stratify=df['labels'], test_size=0.3)\n",
        "X_test, X_val, _, _ = train_test_split(X_test, X_test['labels'], stratify=X_test['labels'], test_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGrQVkXJN2dq"
      },
      "outputs": [],
      "source": [
        "X_train['Type'] = 'train'\n",
        "X_test['Type'] = 'test'\n",
        "X_val['Type'] = 'val'\n",
        "df = pd.concat([X_train,X_test, X_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39FzATqUNMNl"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dERdApo6OMAM"
      },
      "outputs": [],
      "source": [
        "for name in Names:\n",
        "  os.system(f\"mkdir data/train/'{name}'\") \n",
        "  os.system(f\"mkdir data/test/'{name}'\")\n",
        "  os.system(f\"mkdir data/val/'{name}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NODa2Yi8OL7A"
      },
      "outputs": [],
      "source": [
        "from shutil import copyfile\n",
        "for i,row in df.iterrows():\n",
        "    section = row['Type']\n",
        "    ipath = row['image_urls']\n",
        "    #print(ipath, opath)\n",
        "    opath = ipath.replace(f\"images/Image_Database_Munchies/\",f\"data/{section}/\")\n",
        "    copyfile(ipath, opath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8yxWSOZPHQz"
      },
      "outputs": [],
      "source": [
        "traindir = '/content/data/train'\n",
        "testdir = '/content/data/test'\n",
        "valdir ='/content/data/val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njG8Bq51PLsV"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "image_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(degrees=25),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) \n",
        "    ]),\n",
        "\n",
        "    'test':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]), \n",
        "    \n",
        "    'val':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs9RnFg7OL1X"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "data = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
        "    'test':\n",
        "    datasets.ImageFolder(root=testdir, transform=image_transforms['test']), \n",
        "    'val':\n",
        "    datasets.ImageFolder(root=testdir, transform=image_transforms['val'])\n",
        "} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdR2FyLCPS50"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def imshow_tensor(image, ax=None, title=None):\n",
        "\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    plt.axis('off')\n",
        "\n",
        "    return ax, image "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F66ILBhqOLv5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "data = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
        "    'test':\n",
        "    datasets.ImageFolder(root=testdir, transform=image_transforms['test']),\n",
        "    'val':\n",
        "    datasets.ImageFolder(root=testdir, transform=image_transforms['val'])\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True,num_workers=2),\n",
        "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True,num_workers=2),\n",
        "    'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True,num_workers=2)\n",
        "} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heP_d7_EPuDB"
      },
      "outputs": [],
      "source": [
        "trainiter = iter(dataloaders['train'])\n",
        "features, labels = next(trainiter)\n",
        "features.shape, labels.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezn6miqiP0Zt"
      },
      "outputs": [],
      "source": [
        "#Function to train Model:\n",
        "from timeit import default_timer as timer\n",
        "def train(model,criterion,optimizer,train_loader, valid_loader, n_epochs=20, print_every=1):\n",
        "  history = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0\n",
        "    valid_loss = 0.0\n",
        "    valid_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    start = timer()\n",
        "\n",
        "    for i, (data, target) in enumerate(train_loader):\n",
        "      if train_on_gpu: \n",
        "        data, target = data.cuda(), target.cuda()\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      loss = criterion(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item() * data.size(0)\n",
        "      _, pred = torch.max(output, dim=1)\n",
        "      correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "      accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "      train_acc += accuracy.item() * data.size(0)\n",
        "    \n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data, target in valid_loader:\n",
        "          if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "          output = model(data)\n",
        "          loss = criterion(output, target)\n",
        "          valid_loss += loss.item()*data.size(0)\n",
        "          _, pred = torch.max(output, dim=1)\n",
        "          correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "          accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "          valid_acc += accuracy.item()*data.size(0)\n",
        "\n",
        "  train_loss = train_loss / len(train_loader.dataset)\n",
        "  train_acc = train_acc / len(train_loader.dataset)\n",
        "  valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "  valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "  history.append([train_loss, train_acc, valid_loss, valid_acc])\n",
        "\n",
        "  model.optimizer = optimizer\n",
        "  total_time = timer() \n",
        "  history = pd.DataFrame(history,columns=['Train_loss', 'Train_acc', 'Val_loss', 'Val_ac'])\n",
        "\n",
        "  return model, history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to process an Image path into a Tensor:\n",
        "from PIL import Image\n",
        "def process_image(image_path):\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    img = image.resize((256, 256))\n",
        "\n",
        "    width = 256\n",
        "    height = 256\n",
        "    new_width = 224\n",
        "    new_height = 224\n",
        "\n",
        "    left = (width - new_width) / 2\n",
        "    top = (height - new_height) / 2\n",
        "    right = (width + new_width) / 2\n",
        "    bottom = (height + new_height) / 2\n",
        "    img = img.crop((left, top, right, bottom))\n",
        "    img = np.array(img).transpose((2, 0, 1)) / 256\n",
        "    means = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
        "    stds = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
        "\n",
        "    img = img - means\n",
        "    img = img / stds\n",
        "\n",
        "    img_tensor = torch.Tensor(img)\n",
        "\n",
        "    return img_tensor"
      ],
      "metadata": {
        "id": "6dRTB_soUgHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to make predictions on a single image:\n",
        "def predict(image_path, model, topk=3):\n",
        "    real_class = image_path.split('/')[-2]\n",
        "\n",
        "    img_tensor = process_image(image_path)\n",
        "\n",
        "    if train_on_gpu:\n",
        "        img_tensor = img_tensor.view(1, 3, 224, 224).cuda()\n",
        "    else:\n",
        "        img_tensor = img_tensor.view(1, 3, 224, 224)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        out = model(img_tensor)\n",
        "        ps = torch.exp(out)\n",
        "\n",
        "        #Top 3 predictions\n",
        "        topk, topclass = ps.topk(topk, dim=1)\n",
        "        top_classes = [\n",
        "            model.idx_to_class[class_] for class_ in topclass.cpu().numpy()[0]\n",
        "        ]\n",
        "        top_p = topk.cpu().numpy()[0]\n",
        "\n",
        "        return img_tensor.cpu().squeeze(), top_p, top_classes, real_class"
      ],
      "metadata": {
        "id": "YbSrTV0-UlS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to display Image and Predictions:\n",
        "def display_prediction(image_path, model, topk):\n",
        "    img, ps, classes, y_obs = predict(image_path, model, topk)\n",
        "    result = pd.DataFrame({'p': ps}, index=classes)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    ax = plt.subplot(1, 2, 1)\n",
        "    ax, img = imshow_tensor(img, ax=ax)\n",
        "    ax.set_title(y_obs, size=20)\n",
        "\n",
        "    ax = plt.subplot(1, 2, 2)\n",
        "    #Bar plot\n",
        "    result.sort_values('p')['p'].plot.barh(color='#2e4d7d', edgecolor='k', ax=ax)\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.tight_layout()"
      ],
      "metadata": {
        "id": "7ubraVQeX1-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target, topk=(1, )):\n",
        "    if train_on_gpu:\n",
        "        output = output.to('cuda')\n",
        "        target = target.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size).item())\n",
        "        return res"
      ],
      "metadata": {
        "id": "tNj8F1ZMZaU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, criterion, topk=(1, 2, 3)):\n",
        "    confusion_matrix = torch.zeros(n_classes, n_classes)\n",
        "    classes = []\n",
        "    losses = []\n",
        "    acc_results = np.zeros((len(test_loader.dataset), len(topk)))\n",
        "    i = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, targets in test_loader:\n",
        "            if train_on_gpu:\n",
        "                data, targets = data.to('cuda'), targets.to('cuda')\n",
        "\n",
        "            out = model(data)\n",
        "            _, predscm = torch.max(out, 1)\n",
        "            for t, p in zip(targets.view(-1), predscm.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "          \n",
        "            for pred, true in zip(out, targets):\n",
        "                acc_results[i, :] = accuracy(\n",
        "                    pred.unsqueeze(0), true.unsqueeze(0), topk)\n",
        "                classes.append(model.idx_to_class[true.item()])\n",
        "                loss = criterion(pred.view(1, n_classes), true.view(1))\n",
        "                losses.append(loss.item())\n",
        "                i += 1\n",
        "\n",
        "    results = pd.DataFrame(acc_results, columns=[f'top{i}' for i in topk])\n",
        "    results['class'] = classes\n",
        "    results['loss'] = losses\n",
        "    results = results.groupby(classes).mean()\n",
        "\n",
        "    return results.reset_index().rename(columns={'index': 'class'}),confusion_matrix\n",
        "\n",
        "criterion = torch.nn.NLLLoss()"
      ],
      "metadata": {
        "id": "0-uHhsr_ZfHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else '.0f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    return plt"
      ],
      "metadata": {
        "id": "JMq_4yuAZiQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pretrained ResNet50\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rM64rcL_ftza"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbwEULWmOLqw"
      },
      "outputs": [],
      "source": [
        "#Model:\n",
        "from torchvision import models\n",
        "model = models.resnet50(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iJRaPxVPz4i"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43TTaL4FPzva"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "n_inputs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),\n",
        "                      nn.LogSoftmax(dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdG3c5TkP084"
      },
      "outputs": [],
      "source": [
        "model.fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_puNqDRP01P"
      },
      "outputs": [],
      "source": [
        "model = model.to('cuda') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiBAVUNHP0tR"
      },
      "outputs": [],
      "source": [
        "model.class_to_idx = data['train'].class_to_idx\n",
        "model.idx_to_class = {\n",
        "    idx: class_\n",
        "    for class_, idx in model.class_to_idx.items()\n",
        "}\n",
        "\n",
        "list(model.idx_to_class.items())[:10] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXnkcvpgP0kl"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "for p in optimizer.param_groups[0]['params']:\n",
        "    if p.requires_grad:\n",
        "        print(p.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEAu-ZkqP0M5"
      },
      "outputs": [],
      "source": [
        "model, history = train(model, criterion, optimizer, dataloaders['train'], dataloaders['val'], n_epochs=10)\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pths = os.listdir(\"/content/data/test/Popchips_Barbeque\")\n",
        "img_path = '/content/data/test/Popchips_Barbeque/'+str(test_pths[0])\n",
        "img, top_p, top_classes, real_class = predict(img_path, model,topk=3)"
      ],
      "metadata": {
        "id": "3tAWu7YnXV6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_p, top_classes"
      ],
      "metadata": {
        "id": "8D-v5QISXyn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_prediction(img_path, model, topk=3)"
      ],
      "metadata": {
        "id": "no4t-w-7ZQ5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results, confusion_matrix = evaluate(model, dataloaders['test'], criterion)"
      ],
      "metadata": {
        "id": "8qhWiwjWZlXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classnames = [model.idx_to_class[i] for i in range(0,n_classes)]\n",
        "plt.figure(figsize=(15,15))\n",
        "plt = plot_confusion_matrix(confusion_matrix, classnames)"
      ],
      "metadata": {
        "id": "UglqGGpqZqFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Overall Accuracy:{(confusion_matrix.diag().sum()/confusion_matrix.sum())*100}%\")"
      ],
      "metadata": {
        "id": "XJ9xZ729aiqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training a ResNet50 from Scratch"
      ],
      "metadata": {
        "id": "BhQI554Df-Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model:\n",
        "from torchvision import models\n",
        "model2 = models.resnet50(pretrained=False)"
      ],
      "metadata": {
        "id": "pTK4AK71f1Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True "
      ],
      "metadata": {
        "id": "gucLqxGkgB59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "n_inputs = model2.fc.in_features\n",
        "model2.fc = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 256),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, n_classes),\n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "metadata": {
        "id": "m7LFUrcvgILj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = model2.to('cuda') "
      ],
      "metadata": {
        "id": "XC2kNBjugYRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.class_to_idx = data['train'].class_to_idx\n",
        "model2.idx_to_class = {\n",
        "    idx: class_\n",
        "    for class_, idx in model2.class_to_idx.items()\n",
        "}\n",
        "\n",
        "list(model2.idx_to_class.items())[:10] "
      ],
      "metadata": {
        "id": "MSD32OBxgeT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "for p in optimizer.param_groups[0]['params']:\n",
        "    if p.requires_grad:\n",
        "        print(p.shape) "
      ],
      "metadata": {
        "id": "BIQ6jGI7gk2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2, history = train(model2, criterion, optimizer, dataloaders['train'], dataloaders['val'], n_epochs=10)\n",
        "history"
      ],
      "metadata": {
        "id": "5x2pTGIbg733"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pths = os.listdir(\"/content/data/test/Popchips_Barbeque\")\n",
        "img_path = '/content/data/test/Popchips_Barbeque/'+str(test_pths[0])\n",
        "img, top_p, top_classes, real_class = predict(img_path, model,topk=3)"
      ],
      "metadata": {
        "id": "nCy2Gqp4jrwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_p, top_classes"
      ],
      "metadata": {
        "id": "T6G1hZqijxF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_prediction(img_path, model2, topk=3)"
      ],
      "metadata": {
        "id": "cr9VzVmCjzki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results, confusion_matrix = evaluate(model2, dataloaders['test'], criterion)"
      ],
      "metadata": {
        "id": "lzs625iYjeqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classnames = [model2.idx_to_class[i] for i in range(0,n_classes)]\n",
        "plt.figure(figsize=(15,15))\n",
        "plt = plot_confusion_matrix(confusion_matrix, classnames)"
      ],
      "metadata": {
        "id": "Pf2ENVe4jj64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Overall Accuracy:{(confusion_matrix.diag().sum()/confusion_matrix.sum())*100}%\")"
      ],
      "metadata": {
        "id": "YQB2O9IFkGwo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}